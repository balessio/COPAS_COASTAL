{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and define functions\n",
    "import cartopy \n",
    "import cartopy.crs as ccrs\n",
    "from global_land_mask import globe\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "from scipy.ndimage.measurements import label\n",
    "from scipy.spatial import ConvexHull\n",
    "from shapely.geometry import Polygon\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "import xarray as xr\n",
    "\n",
    "# initialize custom function\n",
    "    # calculate the approximate distance between two latitude, longitude coordinates\n",
    "def estimate_dist_ll2(lat1, lon1, lat2, lon2):\n",
    "    R_earth = 6371 # radius of earth km\n",
    "    lat1, lon1, lat2, lon2 = np.deg2rad([lat1, lon1, lat2, lon2])\n",
    "    d = np.sin((lat2 - lat1)/2)**2 + np.cos(lat1)*np.cos(lat2) * np.sin((lon2 - lon1)/2)**2\n",
    "    return 2 * R_earth * np.arcsin(np.sqrt(d))\n",
    "\n",
    "    # detect ARs, input east and north IVT vectors as function of lat, lon, and time,\n",
    "    # and the corresponding lat, lon, and time (datetime64) arrays\n",
    "    # follows the methodology of Guan, B., & Waliser, D. E. (2015). \n",
    "    # Detection of atmospheric rivers: Evaluation and application of an\n",
    "    # algorithm for global studies. Journal of Geophysical Research:\n",
    "    # Atmospheres, 120(24), 12514-12535.\n",
    "def detect_ARs(eIVT, nIVT, lat, lon, time,): \n",
    "\n",
    "    poleward_threshold = 50 # kg m^-1 s^-1, must be atleast this poleward\n",
    "    dirDiff_threshold = np.pi / 4 # radians, not part of AR if has IVT difference from mean greater than this\n",
    "    length_threshold = 2000 # km, must be atleast this long\n",
    "    axThresLat, axThresLon = 4, 4 # threshold degrees latitude, longitude of difference between points on axis\n",
    "    bottom_threshold = 100 # kh m^-1 s^-1 absolute minimum IVT for consideration of AR\n",
    "\n",
    "    timePD = pd.to_datetime(time)\n",
    "    # calculate the area of lat-lon grid vs. latitude, store in array\n",
    "    area_vs_lat = np.zeros((lat.size,))\n",
    "    R_earth = 6371 # radius of Earth in km\n",
    "    delta_lon = float(np.abs(lon[2] - lon[1]))\n",
    "    delta_lat = float(np.abs(lat[2] - lat[1]))\n",
    "    for i in range(len(lat)):\n",
    "        if abs(lat[i]) == 90:\n",
    "            sgnPole = np.sign(lat[i])\n",
    "            lat1 = np.deg2rad(sgnPole * 90)\n",
    "            lat2 = np.deg2rad(sgnPole * (90 - delta_lat/2))\n",
    "            area_vs_lat[i] = 2 * (np.sin(lat1) - np.sin(lat2))\n",
    "        else:\n",
    "            lat1 = np.deg2rad(lat[i] + delta_lat/2)\n",
    "            lat2 = np.deg2rad(lat[i] - delta_lat/2)\n",
    "            area_vs_lat[i] = np.sin(lat1) - np.sin(lat2)\n",
    "    area_vs_lat = np.abs(area_vs_lat) * np.pi/180 * R_earth**2 * delta_lon\n",
    "\n",
    "    # store information for calculating 5-month moving percentiles\n",
    "    months = [pd.to_datetime(str(timePD[0].month) + '-' + str(timePD[0].year))]\n",
    "    lens_months = []\n",
    "    currentMonth = timePD[0].month\n",
    "    # one entry for each month of data, assumes no months are skipped\n",
    "    for i in range(1, len(timePD)):\n",
    "        if timePD[i].month != currentMonth:\n",
    "            currentMonth = timePD[i].month\n",
    "            months.append(pd.to_datetime(str(timePD[i].month) + '-' + str(timePD[i].year)))\n",
    "            lens_months.append(timePD[i-1].day)\n",
    "    lens_months.append(timePD[-1].day)\n",
    "    lens_months, months = np.array(lens_months), np.array(months)\n",
    "\n",
    "    # calculate the IVT magnitude\n",
    "    magIVT_allTime = np.zeros((len(timePD),eIVT[0].shape[0], eIVT[0].shape[1]))\n",
    "    for i in range(len(timePD)):\n",
    "        magIVT_allTime[i] = np.sqrt(np.power(eIVT[i], 2) + np.power(nIVT[i], 2))\n",
    "\n",
    "    # calculate the percentiles\n",
    "    percentiles_dict = {}\n",
    "    des_percentiles = [85, 87.5, 90, 92.5, 95, 97.5]\n",
    "    for des_perc in des_percentiles:\n",
    "        percentiles = np.zeros((len(months),eIVT[0].shape[0], eIVT[0].shape[1]))\n",
    "        if len(months) < 4:\n",
    "            prctlFrame = np.percentile(magIVT_allTime[:], des_perc, axis=0)\n",
    "            for i in range(len(months)): percentiles[i] = prctlFrame\n",
    "        elif len(months) == 4:\n",
    "            percentiles[0] = np.percentile(magIVT_allTime[:np.sum(lens_months[:3])], des_perc, axis=0)\n",
    "            percentiles[-1] = np.percentile(magIVT_allTime[lens_months[1]:], des_perc, axis=0)\n",
    "            prctlFrame = np.percentile(magIVT_allTime[:], des_perc, axis=0)\n",
    "            for i in range(1,3): percentiles[i] = prctlFrame\n",
    "        else:\n",
    "            percentiles[0] = np.percentile(magIVT_allTime[:np.sum(lens_months[:3])], des_perc, axis=0)\n",
    "            percentiles[1] = np.percentile(magIVT_allTime[:np.sum(lens_months[:4])], des_perc, axis=0)\n",
    "            percentiles[-1] = np.percentile(\n",
    "                magIVT_allTime[-1*np.sum(lens_months[-3:]):], des_perc, axis=0)\n",
    "            percentiles[-2] = np.percentile(\n",
    "                magIVT_allTime[-1*np.sum(lens_months[-4:]):], des_perc, axis=0)\n",
    "            for i in range(2,len(months)-2):\n",
    "                i1 = np.sum(lens_months[:i-2])\n",
    "                i2 = i1 + np.sum(lens_months[i-2:i+3])\n",
    "                percentiles[i] = np.percentile(magIVT_allTime[i1:i2], des_perc, axis=0)\n",
    "        percentiles_dict[str(des_perc)] = percentiles\n",
    "\n",
    "    # AR detection code\n",
    "    structure = np.ones((3, 3), dtype = int)\n",
    "    geodesic = pyproj.Geod(ellps='WGS84')\n",
    "\n",
    "    # arrays to hold the data about the detected ARs\n",
    "    ARdatetime, ARmeanMagIVT, ARmeanDirIVT = [], [], []\n",
    "    ARlength, ARwidth, ARperimeterLon, ARperimeterLat = [], [], [], []\n",
    "    ARbottomAxisLat, AReastAxisLon, ARtopAxisLat, ARwestAxisLon, ARlandfall = [], [], [], [], []\n",
    "\n",
    "    reasonsForSkip = ['near equator', 'not poleward enough',\n",
    "        'IVT direction different from elongation direction', 'too much variation in IVT direction',\n",
    "        'not long enough', 'too wide']\n",
    "    skipped = [0,0,0,0,0,0]\n",
    "\n",
    "    for i in range(len(timePD)):\n",
    "        # hold data for plotting\n",
    "        validARcolsPost = np.zeros(eIVT[0].shape)\n",
    "        axLatAll, axLonAll, sizeAx = [], [], []\n",
    "        # magnitude of the IVT\n",
    "        magIVT = np.copy(magIVT_allTime[i])\n",
    "        # find which percentile frame to use\n",
    "        prctlInd = np.searchsorted(\n",
    "            months, pd.to_datetime(str(timePD[i].month) + '-' + str(timePD[i].year)))\n",
    "\n",
    "        # iterate through percentiles\n",
    "        for des_perc in des_percentiles:\n",
    "            # true where threshold requirement is satisfied\n",
    "            validARcols = (magIVT > percentiles_dict[str(des_perc)][prctlInd]) * (\n",
    "                magIVT > bottom_threshold)\n",
    "            # hold the coordinates of all groups of \"true\" values, labeled by number\n",
    "            labeled, ncomponents = label(validARcols.astype(int), structure)\n",
    "\n",
    "            # connect shapes the straddle longitude = 0deg\n",
    "            if np.max(lon) - np.min(lon) >= 360 - delta_lon:\n",
    "                for y in range(labeled.shape[0]):\n",
    "                    if labeled[y, 0] > 0 and labeled[y, -1] > 0 and labeled[y,0] != labeled[y,-1]:\n",
    "                        labeled[labeled == labeled[y, -1]] = labeled[y, 0]\n",
    "                        ncomponents -= 1\n",
    "                for j in range(1,ncomponents + 1):\n",
    "                    if np.where(labeled==j)[0].size == 0:\n",
    "                        labeled[labeled == labeled.max()] = j\n",
    "            \n",
    "            # iterate through each shape to consider further AR requirements\n",
    "            j = 1\n",
    "            while j <= ncomponents:\n",
    "                ind_lat, ind_lon = np.where(labeled == j)\n",
    "                # skip if if straddles the equator\n",
    "                #if np.min(np.abs(lat[ind_lat])) < 2*delta_lat:\n",
    "                #    skipped[0] += 1\n",
    "                #    j += 1\n",
    "                #    continue\n",
    "                mean_lat = lat[ind_lat].mean()\n",
    "                nIVT_t = np.array(nIVT[i])[ind_lat, ind_lon]\n",
    "                # skip if no appreciable poleward IVT\n",
    "                if nIVT_t.mean() * np.sign(mean_lat) < poleward_threshold:\n",
    "                    skipped[1] += 1\n",
    "                    j += 1\n",
    "                    continue \n",
    "                eIVT_t = np.array(eIVT[i])[ind_lat, ind_lon]\n",
    "                # direction of IVT in radians for each column\n",
    "                dirIVT = np.arctan2(nIVT_t, eIVT_t)\n",
    "                meanDir = dirIVT.mean()\n",
    "                # find the two coordinates in the blob furthest apart\n",
    "                inds_f = [0, -1] # index for ind_lon,lat of two furthest points\n",
    "                ixLon, inLon = -1*np.argmax(np.flip(ind_lon))-1, np.argmin(ind_lon)\n",
    "                zonal = True\n",
    "                thruLon0 = (np.max(lon[ind_lon]) - np.min(lon[ind_lon])) >= 360 - 2*delta_lon\n",
    "                if len(np.unique(ind_lon)) > len(np.unique(ind_lat)):\n",
    "                    zonal = False\n",
    "                    if not thruLon0: inds_f = [ixLon, inLon]\n",
    "                    else:\n",
    "                        ixLon = np.argmax(\n",
    "                            np.array(lon[ind_lon]) * (np.array(lon[ind_lon]) < 180))\n",
    "                        inLon = np.argmin(\n",
    "                            np.array(lon[ind_lon]) + 360*(np.array(lon[ind_lon]) <= 180))\n",
    "                        inds_f = [ixLon, inLon]\n",
    "                # skip if mean direction differs from direction of elongation by > 45 degrees \n",
    "                fwd_azimuth, back_azimuth, distance = geodesic.inv(\n",
    "                    lon[ind_lon[inds_f[0]]], lat[ind_lat[inds_f[0]]],\n",
    "                    lon[ind_lon[inds_f[1]]], lat[ind_lat[inds_f[1]]])\n",
    "                if np.abs(np.abs(meanDir) + np.pi/2 - np.abs(\n",
    "                    np.deg2rad(fwd_azimuth))) > dirDiff_threshold:\n",
    "                    skipped[2] += 1\n",
    "                    j += 1\n",
    "                    continue\n",
    "                # skip if more than half differ by > direction threshold from the mean direction\n",
    "                if (np.abs(dirIVT - meanDir) > dirDiff_threshold).sum() > len(ind_lat)/2:\n",
    "                    skipped[3] += 1\n",
    "                    j += 1\n",
    "                    continue\n",
    "                # divide into segments to calculate axis\n",
    "                perimLat, perimLon = [], []\n",
    "                perimLatFor, perimLatBack, perimLonFor, perimLonBack = [], [], [], []\n",
    "                if zonal:\n",
    "                    indNewSeg = (np.where((ind_lat[1:] - ind_lat[:-1]) > 0) + np.array([1]))[0]\n",
    "                    if len(indNewSeg) < 2:\n",
    "                        skipped[4] += 1\n",
    "                        j += 1\n",
    "                        continue\n",
    "                    klat = ind_lat[0]\n",
    "                    klon = ind_lon[np.argmax(magIVT[[klat],ind_lon[:indNewSeg[0]]])]\n",
    "                    axLon, axLat = [klon], [klat]\n",
    "                    for k in range(1, len(indNewSeg)):\n",
    "                        klat = ind_lat[indNewSeg[k]]\n",
    "                        klon = ind_lon[indNewSeg[k-1] + np.argmax(\n",
    "                            magIVT[[klat],ind_lon[indNewSeg[k-1]:indNewSeg[k]]])]\n",
    "                        perimLat.extend([lat[klat] - delta_lat/2, lat[klat] + delta_lat/2])\n",
    "                        perimLonFor.extend(\n",
    "                            [lon[ind_lon[indNewSeg[k-1]]] + delta_lon/2, lon[ind_lon[indNewSeg[k-1]]]\\\n",
    "                                + delta_lon/2])\n",
    "                        perimLonBack.extend(\n",
    "                            [lon[ind_lon[indNewSeg[k]-1]] - delta_lon/2, lon[ind_lon[indNewSeg[k]-1]]\\\n",
    "                                - delta_lon/2])\n",
    "                        axLon.append(klon)\n",
    "                        axLat.append(klat)\n",
    "                    perimLat = perimLat + perimLat[::-1]\n",
    "                    perimLon = perimLonFor + perimLonBack[::-1]\n",
    "                    axisShaper = np.where(np.abs(\n",
    "                        np.array(axLon[1:]) - np.array(axLon[:-1]))*delta_lon > axThresLon)[0] + 1\n",
    "                    if len(axisShaper) > 0:\n",
    "                        j += 1\n",
    "                        continue\n",
    "                else:\n",
    "                    sortedByLon = np.asarray(sorted(zip(ind_lon, ind_lat)))\n",
    "                    ind_lon, ind_lat = sortedByLon[:,0], sortedByLon[:,1]\n",
    "                    if thruLon0:\n",
    "                        indSplit = np.argmax(np.array(ind_lon[1:]) - np.array(ind_lon[:-1])) + 1\n",
    "                        ind_lon[indSplit:] = ind_lon[indSplit:] - lon.size\n",
    "                        sortedByLon = np.asarray(sorted(zip(ind_lon, ind_lat)))\n",
    "                        ind_lon, ind_lat = sortedByLon[:,0], sortedByLon[:,1]\n",
    "                    indNewSeg = (np.where((ind_lon[1:] - ind_lon[:-1]) > 0) + np.array([1]))[0]\n",
    "                    if len(indNewSeg) < 2:\n",
    "                        skipped[4] += 1\n",
    "                        j += 1\n",
    "                        continue\n",
    "                    klon = ind_lon[0]\n",
    "                    klat = ind_lat[np.argmax(magIVT[ind_lat[:indNewSeg[0]],[klon]])]\n",
    "                    axLon, axLat = [klon], [klat]\n",
    "                    for k in range(1, len(indNewSeg)):\n",
    "                        klon = ind_lon[indNewSeg[k]]\n",
    "                        klat = ind_lat[indNewSeg[k-1] + np.argmax(\n",
    "                            magIVT[ind_lat[indNewSeg[k-1]:indNewSeg[k]],[klon]])]\n",
    "                        perimLon.extend([lon[klon] - delta_lon/2, lon[klon] + delta_lon/2])\n",
    "                        perimLatFor.extend(\n",
    "                            [lat[ind_lat[indNewSeg[k-1]]] + delta_lat/2, lat[ind_lat[indNewSeg[k-1]]]\\\n",
    "                                + delta_lat/2])\n",
    "                        perimLatBack.extend(\n",
    "                            [lat[ind_lat[indNewSeg[k]-1]] - delta_lat/2, lat[ind_lat[indNewSeg[k]-1]]\\\n",
    "                                - delta_lat/2])\n",
    "                        axLon.append(klon)\n",
    "                        axLat.append(klat)\n",
    "                    perimLat = perimLatFor + perimLatBack[::-1]\n",
    "                    perimLon = perimLon + perimLon[::-1]\n",
    "                    axisShaper = np.where(\n",
    "                        np.abs(lat[axLat[1:]] - lat[axLat[:-1]]) > axThresLat)[0] + 1\n",
    "                    if len(axisShaper) > 0:\n",
    "                        j += 1\n",
    "                        continue\n",
    "                        \n",
    "                lat_jump = np.array(np.abs(lat[axLat[1:]] - lat[axLat[:-1]]) < 3)\n",
    "                lon_jump = np.array(np.abs(lon[axLon[1:]] - lon[axLon[:-1]]) < 3)\n",
    "\n",
    "                length = np.abs(np.sum(lat_jump * lon_jump * estimate_dist_ll2(\n",
    "                    np.array(lat[axLat[1:]]), np.array(lon[axLon[1:]]),\n",
    "                    np.array(lat[axLat[:-1]]), np.array(lon[axLon[:-1]]))))\n",
    "                # skip if length under threshold\n",
    "                if length < length_threshold:\n",
    "                    skipped[4] += 1\n",
    "                    j += 1\n",
    "                    continue\n",
    "\n",
    "                area = np.sum(area_vs_lat[ind_lat])\n",
    "                if length**2 / area < 2:\n",
    "                    skipped[5] += 1\n",
    "                    j += 1\n",
    "                    continue\n",
    "\n",
    "                sizeAx.append((len(axLatAll), len(axLatAll) + len(axLat)))\n",
    "                axLatAll.extend(axLat)\n",
    "                axLonAll.extend(axLon)\n",
    "                validARcolsPost[ind_lat, ind_lon] = 1\n",
    "\n",
    "                # add data for valid AR\n",
    "                ARdatetime.append(timePD[i])\n",
    "                ARmeanMagIVT.append(magIVT[ind_lat, ind_lon].mean())\n",
    "                ARmeanDirIVT.append(meanDir)\n",
    "                ARlength.append(length)\n",
    "                ARwidth.append(area / length)\n",
    "\n",
    "                if np.max(perimLon) >= 360-delta_lon and np.min(perimLon) <= delta_lon:\n",
    "                    perimLon -= 360*(perimLon > 180)\n",
    "\n",
    "                ARperimeterLon.append(np.array(perimLon))\n",
    "                ARperimeterLat.append(np.array(perimLat))\n",
    "\n",
    "                AReastAxisLon.append(lon[axLon[0]])\n",
    "                ARbottomAxisLat.append(lat[axLat[0]])\n",
    "                ARwestAxisLon.append(lon[axLon[-1]])\n",
    "                ARtopAxisLat.append(lat[axLat[-1]])\n",
    "                ARlandfall.append(np.any(\n",
    "                    globe.is_land(lat[axLat], lon[axLon] - 360*(lon[axLon] > 180))))\n",
    "\n",
    "                # zero out found ARs\n",
    "                magIVT[ind_lat, ind_lon] = 0\n",
    "\n",
    "                j += 1\n",
    "\n",
    "    ARdatetime = np.array(ARdatetime)\n",
    "    ARmeanMagIVT = np.array(ARmeanMagIVT)\n",
    "    ARmeanDirIVT = np.array(ARmeanDirIVT)\n",
    "    ARlength = np.array(ARlength)\n",
    "    ARwidth = np.array(ARwidth)\n",
    "    ARperimeterLon = np.array(ARperimeterLon, dtype=object)\n",
    "    ARperimeterLat = np.array(ARperimeterLat, dtype=object)\n",
    "    AReastAxisLon = np.array(AReastAxisLon)\n",
    "    ARbottomAxisLat = np.array(ARbottomAxisLat)\n",
    "    ARwestAxisLon = np.array(ARwestAxisLon)\n",
    "    ARtopAxisLat = np.array(ARtopAxisLat)\n",
    "    ARlandfall = np.array(ARlandfall)\n",
    "\n",
    "    results = {\n",
    "        'ARdatetime': ARdatetime,\n",
    "        'ARmeanMagIVT': ARmeanMagIVT,\n",
    "        'ARmeanDirIVT': ARmeanDirIVT,\n",
    "        'ARlength': ARlength,\n",
    "        'ARwidth': ARwidth,\n",
    "        'ARperimeterLon': ARperimeterLon,\n",
    "        'ARperimeterLat': ARperimeterLat,\n",
    "        'AReastAxisLon': AReastAxisLon,\n",
    "        'ARbottomAxisLat': ARbottomAxisLat,\n",
    "        'ARwestAxisLon': ARwestAxisLon,\n",
    "        'ARtopAxisLat': ARtopAxisLat,\n",
    "        'ARlandfall': ARlandfall,\n",
    "    }\n",
    "\n",
    "    print('Recorded ' + str(len(ARdatetime)) + ' ARs!')\n",
    "    print('Skipped enhanced IVT objects for the following reasons:')\n",
    "    for reason, numSkip in zip(reasonsForSkip, skipped):\n",
    "        print('-' + reason + ': ' + str(numSkip) + ' times')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 16:27:38,568 INFO Welcome to the CDS\n",
      "2022-12-02 16:27:38,568 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2022-12-02 16:27:38,906 INFO Request is queued\n",
      "2022-12-02 16:27:40,150 INFO Request is running\n",
      "2022-12-02 16:28:56,290 INFO Request is completed\n",
      "2022-12-02 16:28:56,290 INFO Downloading https://download-0013-clone.copernicus-climate.eu/cache-compute-0013/cache/data8/adaptor.mars.internal-1670009315.7337177-24610-6-12fef7bd-6345-469c-aa8e-cf8702781cf9.nc to IVT_1999.nc (9.9M)\n",
      "2022-12-02 16:29:08,534 INFO Download rate 831.1K/s \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(content_length=10420472,content_type=application/x-netcdf,location=https://download-0013-clone.copernicus-climate.eu/cache-compute-0013/cache/data8/adaptor.mars.internal-1670009315.7337177-24610-6-12fef7bd-6345-469c-aa8e-cf8702781cf9.nc)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example downloading ERA5 IVT data\n",
    "import cdsapi \n",
    "c = cdsapi.Client()\n",
    "c.retrieve(\"reanalysis-era5-single-levels\",\n",
    "{\n",
    "\"variable\": [\n",
    "    \"vertical_integral_of_eastward_water_vapour_flux\",\n",
    "    \"vertical_integral_of_northward_water_vapour_flux\"],\n",
    "# see https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation for all possible\n",
    "# variable names\n",
    "\"product_type\": \"reanalysis\",\n",
    "\"year\": [\"1999\"],\n",
    "\"month\": [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"],\n",
    "\"day\": [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\n",
    "        \"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\n",
    "        \"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\"],\n",
    "\"time\": [\"00:00\", \"12:00\",], # can adjust up to hourly\n",
    "\"area\": [\"0\", \"180\", \"-60\", \"-50\"], # top lat, east lon (-180 -> 180), bottom lat, west lon\n",
    "\"grid\": [\"1.5\", \"1.5\"], # can adjust as fine as 0.25 by 0.25 degrees\n",
    "\"format\": \"netcdf\"\n",
    "}, \"IVT_1999.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded 560 ARs!\n",
      "Skipped enhanced IVT objects for the following reasons:\n",
      "-near equator: 0 times\n",
      "-not poleward enough: 36509 times\n",
      "-IVT direction different from elongation direction: 19057 times\n",
      "-too much variation in IVT direction: 357 times\n",
      "-not long enough: 9098 times\n",
      "-too wide: 8 times\n"
     ]
    }
   ],
   "source": [
    "# example usage of AR detector\n",
    "\n",
    "# open dataset\n",
    "data = xr.open_dataset('IVT_1999.nc')\n",
    "data # display data info\n",
    "time = data.variables['time']\n",
    "# longitude array deg\n",
    "lon = data.variables['longitude']\n",
    "# latitude array deg\n",
    "lat = data.variables['latitude'] \n",
    "# total column water vapor grid kg m^-2\n",
    "#tcwv = data.variables['tcwv'] \n",
    "# eastward component of vertically integrated water vapor kg m^-1 s^-1\n",
    "eIVT = data.variables['p71.162'] \n",
    "# northward component of vertically integrated water vapor kg m^-1 s^-1\n",
    "nIVT = data.variables['p72.162']\n",
    "\n",
    "# results is a dictionary with the following keys:\n",
    "# 'ARdatetime', 'ARmeanMagIVT', 'ARmeanDirIVT', 'ARlength', 'ARwidth',\n",
    "# 'ARperimeterLon', 'ARperimeterLat', 'AReastAxisLon', 'ARbottomAxisLat',\n",
    "# 'ARwestAxisLon', 'ARtopAxisLat', 'ARlandfall'\n",
    "results = detect_ARs(eIVT, nIVT, lat, lon, time,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
